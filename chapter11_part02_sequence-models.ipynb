{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Processing words as a sequence: the Sequence Model approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A first practical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Downloading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "base_dir = pathlib.Path(\"../dlkeras/aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21002 files belonging to 3 classes.\n",
      "Found 3972 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"../dlkeras/aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"../dlkeras/aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"../dlkeras/aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_record = train_ds.take(1).get_single_element()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_label = train_ds.take(1).get_single_element()[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I used to LOVE this movie as a kid but, seeing it again 20+ years later, it actually sucks. Up The Academy might have been ahead of it's time back in 1980, but it has almost nothing to offer today! Movies like Caddyshack and Stripes hold-up much better today than this steaming dogpile. No T&A. No great jokes except for the one-liners we've all heard a million times by now.<br /><br />I recently bought the DVD in hopes that it would be the gem I remembered it being. Well, I was WAY off! The soundtrack had only 2-3 widely-recognizable hits (not the smash compilation others had mentioned) and the frequent voice-overs were terrible. The only thing that was interesting, to me, was predicting what the character's lines were before they said them. Yep, I watched this movie that much back then! <br /><br />The only reason I am writing this review is to give my two cents on why this movie should be forgotten, sorry to say. :(\",\n",
       " 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_record.numpy().decode('utf8'), one_label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Now please don\\'t start calling me names like, \"unpatriotic\" , \"weirdo\" and more .<br /><br />The very length of this movie (4 hours .. !!!) is its biggest mistake . No editing at all - seems like J.P. Dutta fell in love with his project too much . Even Lagaan was 4 hours long - but it was entertaining and gave a message as well .<br /><br />It\\'s based on true incidents and real people . Kudos to it , but were the repetitive war scenes really needed ? On top of it the focus constantly shifted from one battalion / squadron to another and it was impossible to keep a track of them all .<br /><br />Between the skirmishes , there were songs about loneliness , lovesickness and related stuff . There were chummy conversations . In the beginning it gave some relief from the violence but became so monotonous later that one could even correctly predict nature of the forthcoming talk .<br /><br />Why were the soldiers walking around as if they were lions in jungle , fully unaware that enemy was lurking somewhere near? And when they were shot , it elicited sympathy but it seemed unmindful of them to be so cocksure of their safety in the first place .<br /><br />Music was melodious and the lyrics were soulful but did not fit with the movie . Better to listen to them on the soundtrack rather than in the movie .<br /><br />Acting was the saving grace : From seasoned veterans like Sanjay Dutt and Ajay Devgan , to relative newbies like Abhishek Bachchan and Akshaye Khanna , everyone acted like a pro . Manoj Bajpai and Ashutosh Rana deserve a special mention for lightening up the mood whenever necessary .<br /><br />Dialogues ranged from brilliant (\"From Madhuri .. with Love!!\") to illogical / monotonous (\"Pakistan se zyada musalman Hindusthan mein hain\") . And the expletive spree consisting of all the MCs , BCs , Cs and F-words wasn\\'t really required . <br /><br />LOC Kargil attempts to provide a fitting tribute to the brave Indian soldiers , but tries too hard and ultimately fails . Indian soldiers surely deserve a better tribute .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only_train_ds.take(1).get_single_element()[2].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing integer sequence datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A sequence model built on top of one-hot encoded vector sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-02-16 14:53:15.805 tensorflow-2-6-gpu-ml-g4dn-2xlarge-19b876f82216afed60344884c91d:20 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-02-16 14:53:15.829 tensorflow-2-6-gpu-ml-g4dn-2xlarge-19b876f82216afed60344884c91d:20 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "tf.one_hot (TFOpLambda)      (None, None, 20000)       0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                5128448   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,128,513\n",
      "Trainable params: 5,128,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a first basic sequence model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "657/657 [==============================] - 154s 229ms/step - loss: -15.5739 - accuracy: 0.4755 - val_loss: 31.7995 - val_accuracy: 0.3706\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 150s 228ms/step - loss: -37.2452 - accuracy: 0.4761 - val_loss: 57.5315 - val_accuracy: 0.3706\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 150s 228ms/step - loss: -58.7439 - accuracy: 0.4761 - val_loss: 83.2285 - val_accuracy: 0.3706\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 151s 229ms/step - loss: -80.0520 - accuracy: 0.4761 - val_loss: 108.9544 - val_accuracy: 0.3706\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 149s 227ms/step - loss: -101.4234 - accuracy: 0.4761 - val_loss: 134.6875 - val_accuracy: 0.3706\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 153s 233ms/step - loss: -122.8416 - accuracy: 0.4761 - val_loss: 160.3985 - val_accuracy: 0.3706\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 154s 235ms/step - loss: -144.3369 - accuracy: 0.4761 - val_loss: 186.1523 - val_accuracy: 0.3706\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 151s 229ms/step - loss: -165.3614 - accuracy: 0.4761 - val_loss: 211.8475 - val_accuracy: 0.3706\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 149s 227ms/step - loss: -187.2864 - accuracy: 0.4761 - val_loss: 237.5943 - val_accuracy: 0.3706\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 150s 229ms/step - loss: -208.6259 - accuracy: 0.4761 - val_loss: 263.2955 - val_accuracy: 0.3706\n",
      "782/782 [==============================] - 94s 119ms/step - loss: 25.2615 - accuracy: 0.5000\n",
      "Test acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 93s 119ms/step - loss: 25.2615 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "evluacion_modelo = model.evaluate(int_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Understanding word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Learning word embeddings with the `Embedding` layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Instantiating an `Embedding` layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Model that uses an Embedding layer trained from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 256)         5120000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                73984     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 32s 44ms/step - loss: -15.9390 - accuracy: 0.4755 - val_loss: 32.1629 - val_accuracy: 0.3706\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -37.4479 - accuracy: 0.4761 - val_loss: 57.8623 - val_accuracy: 0.3706\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -58.9265 - accuracy: 0.4761 - val_loss: 83.5956 - val_accuracy: 0.3706\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -80.3856 - accuracy: 0.4761 - val_loss: 109.2937 - val_accuracy: 0.3706\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -101.7467 - accuracy: 0.4761 - val_loss: 135.0506 - val_accuracy: 0.3706\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -123.1733 - accuracy: 0.4761 - val_loss: 160.7907 - val_accuracy: 0.3706\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -144.2704 - accuracy: 0.4761 - val_loss: 186.5087 - val_accuracy: 0.3706\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -166.0503 - accuracy: 0.4761 - val_loss: 212.2353 - val_accuracy: 0.3706\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -187.6221 - accuracy: 0.4761 - val_loss: 237.9989 - val_accuracy: 0.3706\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 28s 43ms/step - loss: -208.9493 - accuracy: 0.4761 - val_loss: 263.6972 - val_accuracy: 0.3706\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 25.5502 - accuracy: 0.5000\n",
      "Test acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Understanding padding & masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Model that uses an Embedding layer trained from scratch, with masking enabled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 256)         5120000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                73984     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,194,049\n",
      "Trainable params: 5,194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 37s 47ms/step - loss: -16.0371 - accuracy: 0.4755 - val_loss: 32.3896 - val_accuracy: 0.3706\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -37.7602 - accuracy: 0.4761 - val_loss: 58.1156 - val_accuracy: 0.3706\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -59.0116 - accuracy: 0.4761 - val_loss: 83.8140 - val_accuracy: 0.3706\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -80.4339 - accuracy: 0.4761 - val_loss: 109.5257 - val_accuracy: 0.3706\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -101.6949 - accuracy: 0.4761 - val_loss: 135.1934 - val_accuracy: 0.3706\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -123.3134 - accuracy: 0.4761 - val_loss: 160.9404 - val_accuracy: 0.3706\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -144.8868 - accuracy: 0.4761 - val_loss: 186.6857 - val_accuracy: 0.3706\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -166.2490 - accuracy: 0.4761 - val_loss: 212.4371 - val_accuracy: 0.3706\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -187.2768 - accuracy: 0.4761 - val_loss: 238.1796 - val_accuracy: 0.3706\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 29s 44ms/step - loss: -208.9726 - accuracy: 0.4761 - val_loss: 263.8873 - val_accuracy: 0.3706\n",
      "782/782 [==============================] - 18s 20ms/step - loss: 25.7301 - accuracy: 0.5000\n",
      "Test acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(\n",
    "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Downloading the GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-16 17:39:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-02-16 17:39:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-02-16 17:39:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.30MB/s    in 2m 39s  \n",
      "\n",
      "2022-02-16 17:42:16 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Parsing the GloVe word-embeddings file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Loading the GloVe embeddings in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the GloVe word-embeddings matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    max_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Training a simple bidirectional LSTM on top of the GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Model that uses aget_single_elementetrained Embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,034,113\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 34s 43ms/step - loss: -15.2848 - accuracy: 0.4761 - val_loss: 31.4081 - val_accuracy: 0.3706\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -36.9054 - accuracy: 0.4761 - val_loss: 57.1390 - val_accuracy: 0.3706\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -58.3353 - accuracy: 0.4761 - val_loss: 82.8500 - val_accuracy: 0.3706\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -79.7061 - accuracy: 0.4761 - val_loss: 108.5489 - val_accuracy: 0.3706\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -101.0733 - accuracy: 0.4761 - val_loss: 134.3025 - val_accuracy: 0.3706\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -122.2318 - accuracy: 0.4761 - val_loss: 160.0150 - val_accuracy: 0.3706\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -143.9525 - accuracy: 0.4761 - val_loss: 185.6909 - val_accuracy: 0.3706\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -165.4025 - accuracy: 0.4761 - val_loss: 211.3945 - val_accuracy: 0.3706\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -186.6399 - accuracy: 0.4761 - val_loss: 237.1031 - val_accuracy: 0.3706\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 26s 40ms/step - loss: -208.2790 - accuracy: 0.4761 - val_loss: 262.8741 - val_accuracy: 0.3706\n",
      "782/782 [==============================] - 17s 19ms/step - loss: 24.9494 - accuracy: 0.5000\n",
      "Test acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<MapDataset shapes: ((None, 600), (None,)), types: (tf.int64, tf.int32)>,\n",
       " <MapDataset shapes: ((None, 600), (None,)), types: (tf.int64, tf.int32)>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_train_ds, int_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(600,), dtype=int64, numpy=\n",
       " array([  713,   422,    21,     2,  3751,     7,    31,  2584,    27,\n",
       "           14,   323,  1423,   148,     6,   412,    31,  6851,    27,\n",
       "          287,     2,  1299,     5,     4,  2694,     1,     7,    34,\n",
       "            1,  7158,    37,    14, 14070,    17,  8643,     1,  3920,\n",
       "           31,     2,   575,     5,    29,    31,   575,     5,  6851,\n",
       "           99,     2,   112,  1798,    23,  6063,   148,   166,     1,\n",
       "          158,   138,    74,    27,   847,     6,   208,     6,     2,\n",
       "          169,     6,   400,     2,  1030,    37,   299,    12,    27,\n",
       "           60,    26,    61,  1423,   148,     6,   412,    27,   444,\n",
       "            6,   120,     2,  1030,    12,    27,     7,   123,  1181,\n",
       "            3,     1, 15532,  5548,   137,   124,   490,     7,    15,\n",
       "           50,    15,  1955,    56,    10,    26,   107,    11,   768,\n",
       "           13,   516,    30,  7722,     6,   412,    53,    32,    27,\n",
       "           69,   829,     7,    23,   313,     1,  4426,    18,   137,\n",
       "          121,    27,    26,    39,    73,  2458,  1798,     2,  1030,\n",
       "           37, 14070,    23,  3920,  6851,   148,   592,    23,  1030,\n",
       "           41,   562,    23,  1595,    12,   442,    21,     2,  3100,\n",
       "          492,    82,    17,    23,  3920,   464,   412,   206,   713,\n",
       "            2,   215,     5,    89,   741,    57,    31,   166,  3862,\n",
       "         1409,    16,   137,     7,  5097,   187,    11,   166,  1030,\n",
       "            8,     2,   169,     7,     4,  1299,     5,    23,  2694,\n",
       "           48,    25,    39,   105,   181,    71,   231,    28,   895,\n",
       "            8,     1,   118,    87,    69,    27,    97,   144,  8768,\n",
       "           17,     2,  2385,     5,    61,    29,  4426,    87,    69,\n",
       "           27,   138,   140,  2827,   445,   130,   481,  5729,    21,\n",
       "          376,    87,   117,    27,    46,  1481,    23,  3862,     1,\n",
       "           87,   121,    27,   828,  2064,    53,    81,    82,   163,\n",
       "           31,    89,    38,   281,    31,     4,   648,  1731,     2,\n",
       "           19,   562,   169,   587,     5,    12,   304,     2,  1555,\n",
       "          182,     4,  1152,     3,   283,    57,     4,  1155,     6,\n",
       "          377,     1,     6,   120,    57,    31,    23,   166,  3862,\n",
       "         1409,     8,   647,     6,   120,    89,    12,    27,     7,\n",
       "          123,  1181,    10,   199,     9,    14,     4,  1027,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0])>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "int_train_ds.take(1).get_single_element()[1][0], int_train_ds.take(1).get_single_element()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11_part02_sequence-models.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
